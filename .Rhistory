#### List papers ####
kable(
work_table |> filter(type == "Journal") |> select(-type),
escape = FALSE
) |>
kable_styling(
html_font = "IBM Plex Sans",
full_width = FALSE
)
#### List papers ####
kable(
work_table |> filter(type == "Preprint") |> select(-type),
escape = FALSE
) |>
kable_styling(
html_font = "IBM Plex Sans",
full_width = FALSE
)
knitr::opts_chunk$set(
warning = FALSE, message = FALSE
)
library(tidyverse)
library(jsonlite)
library(showtext)
library(patchwork)
library(kableExtra)
library(rorcid)
options(knitr.kable.NA = '')
#### Define ggplot2 theme ####
font_add(
"IBMPlexSans",
regular = "IBMPlexSans-Light.otf",
italic = "IBMPlexSans-LightItalic.otf",
bold = "IBMPlexSans-SemiBold.otf",
bolditalic = "IBMPlexSans-SemiBoldItalic.otf"
)
font_add(
"Futura",
regular = "FuturaStd-Medium.otf",
italic = "FuturaStd-MediumOblique.otf",
bold = "FuturaStd-Bold.otf",
bolditalic = "FuturaStd-BoldOblique.otf",
)
showtext_auto()
textsize <- 22
theme_leo <- function(base_size = textsize,
base_family = "Futura") {
theme_minimal(
base_size = base_size,
base_family = base_family
) %+replace%
theme(
strip.text = element_text(hjust = 0, face = "italic"),
axis.ticks = element_blank(),
axis.text.x = element_text(
colour = "white",
margin = margin(1, 1, 1, 1),
size = base_size
),
axis.text.y = element_text(
colour = "white",
angle = 0,
vjust = 0.5,
hjust = 1,
margin = margin(1, 1, 1, 1),
size = base_size
),
panel.border = element_blank(),
axis.title = element_blank(),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
panel.spacing = unit(1.5, "mm"),
legend.position = "bottom",
legend.text = element_text(size = rel(1)),
legend.key.height = unit(4, "mm"),
complete = TRUE
)
}
ggtext_size <- textsize / (14 / 5)
pal_ostwald_disc <- c(
"#275d95",
"#e8c245",
"#d25952"
)
h_index = function(cites) {
if(max(cites) == 0) return(0) # assuming this is reasonable
cites = cites[order(cites, decreasing = TRUE)]
tail(which(cites >= seq_along(cites)), 1)
}
#### Load data ####
orcid <- "0000-0003-3943-1476"
# Other authors for database testing:
# orcid <- "0000-0002-6959-3284" #Edouard
# orcid <- "0000-0002-6377-5132" #Staffan
# full_profile <- fromJSON("https://api.openalex.org/authors/A5046939400") #Lise
full_profile <- fromJSON(paste0("https://api.openalex.org/authors/orcid:", orcid))
full_works <- fromJSON(full_profile[["works_api_url"]])
full_peer_reviews <- orcid_peer_reviews(orcid)[[orcid]][["group"]][["peer-review-group"]] |>
unlist()
short_name <- WikidataR::initials(full_profile[["display_name"]])
works <- tibble(
authorship = full_works[["results"]][["authorships"]],
authors_long = map(authorship, c(2, 2)),
authors_short = map(authors_long, WikidataR::initials),
author_list = map(authors_short, \(x) str_c(x, collapse = ", ")),
title = full_works[["results"]][["title"]],
doi = full_works[["results"]][["doi"]],
journal = full_works[["results"]][["primary_location"]][["source"]][["display_name"]],
jouurnal = case_when(is.na(journal) ~ "", TRUE ~ journal),
version = full_works[["results"]][["best_oa_location"]][["version"]],
type = case_when(version == "submittedVersion" ~ "Preprint", TRUE ~ "Journal"),
pub_year = full_works[["results"]][["publication_year"]],
date = ymd(full_works[["results"]][["publication_date"]]),
cited_by = full_works[["results"]][["cited_by_count"]],
cites_by_year = full_works[["results"]][["counts_by_year"]],
is_oa = full_works[["results"]][["best_oa_location"]][["is_oa"]],
item = paste0(author_list, ". ", pub_year, ". ", title, ". ", "<i>", journal, ".</i> ", "[", str_remove(doi, fixed("https://doi.org/")), "](", doi, ")")
) |>
mutate(
item = str_replace(item, short_name, paste0("<b>", short_name, "</b>")),
item = case_when(
is.na(is_oa) ~ paste0(item, " — [PDF](./assets/pdf/", str_replace_all(str_remove(doi, fixed("https://doi.org/")), "[\\./]", "_") , ".pdf)"),
TRUE ~ item)) |>
arrange(date) |>
drop_na(doi) |>
distinct(title, journal, .keep_all = TRUE)
work_table <- works |>
arrange(desc(date)) |>
select(
"Reference" = item,
"Citations" = cited_by,
"Year" = pub_year,
type
)
work_timeline <- works |>
select(doi, pub_year, type) |>
count(pub_year, type, name = "works") |>
complete(pub_year, type, fill = list(works = 0)) |>
group_by(type) |>
arrange(pub_year) |>
mutate(works_cum = cumsum(works))
cite_timeline <- tibble(
year = full_profile[["counts_by_year"]][["year"]],
cited_by_count = full_profile[["counts_by_year"]][["cited_by_count"]]
) |>
arrange(year)
cites_fiveyear <- works |>
select(doi, pub_year, cites_by_year) |>
unnest(cites_by_year) |>
filter(year > year(now()) - 5) |>
group_by(doi) |>
summarise(cited_by_count = sum(cited_by_count))
cites <- works |>
select(doi, pub_year, cites_by_year) |>
unnest(cites_by_year) |>
group_by(doi) |>
summarise(cited_by_count = sum(cited_by_count))
i10 <- cites |>
filter(cited_by_count >= 10) |>
count() |>
pull(n)
h <- h_index(cites$cited_by_count)
peer_reviews <- tibble(
review = full_peer_reviews[grepl("peer-review-summary.external-ids.external-id.external-id-value", names(full_peer_reviews))],
year = full_peer_reviews[grepl("peer-review-summary.completion-date.year.value", names(full_peer_reviews))]
) |>
summarise(count = n())
peer_reviews_fiveyear <- tibble(
review = full_peer_reviews[grepl("peer-review-summary.external-ids.external-id.external-id-value", names(full_peer_reviews))],
year = full_peer_reviews[grepl("peer-review-summary.completion-date.year.value", names(full_peer_reviews))]
) |>
filter(year > year(now()) - 5) |>
summarise(count = n())
metrics <- tibble(
metric = ordered(
rep(c("Citations", "h index", "i10 index", "Journal articles", "Preprints", "Peer reviews"), 2),
levels = rev(c("Citations", "h index", "i10 index", "Journal articles", "Preprints", "Peer reviews"))
),
span = ordered(
c(rep(c("Total", paste0("Since ", year(now()) - 5)), each = 6)),
levels = c("Total", paste0("Since ", year(now()) - 5))
),
value = c(
sum(cite_timeline$cited_by_count),
h,
i10,
max(work_timeline$works_cum[work_timeline$type == "Journal"]),
max(work_timeline$works_cum[work_timeline$type == "Preprint"]),
peer_reviews$count,
sum(cite_timeline$cited_by_count[cite_timeline$year > year(now()) - 5]),
h_index(cites_fiveyear$cited_by_count),
length(cites_fiveyear$cited_by_count[cites_fiveyear$cited_by_count >= 10]),
sum(work_timeline$works[cite_timeline$year > year(now()) - 5 & work_timeline$type == "Journal"]),
sum(work_timeline$works[cite_timeline$year > year(now()) - 5 & work_timeline$type == "Preprint"]),
peer_reviews_fiveyear$count
))
#### List papers ####
kable(
work_table |> filter(type == "Preprint") |> select(-type),
escape = FALSE
) |>
kable_styling(
html_font = "IBM Plex Sans",
full_width = FALSE
)
View(works)
#### Load data ####
orcid <- "0000-0003-3943-1476"
# Other authors for database testing:
# orcid <- "0000-0002-6959-3284" #Edouard
# orcid <- "0000-0002-6377-5132" #Staffan
# full_profile <- fromJSON("https://api.openalex.org/authors/A5046939400") #Lise
full_profile <- fromJSON(paste0("https://api.openalex.org/authors/orcid:", orcid))
full_works <- fromJSON(full_profile[["works_api_url"]])
full_peer_reviews <- orcid_peer_reviews(orcid)[[orcid]][["group"]][["peer-review-group"]] |>
unlist()
short_name <- WikidataR::initials(full_profile[["display_name"]])
works <- tibble(
authorship = full_works[["results"]][["authorships"]],
authors_long = map(authorship, c(2, 2)),
authors_short = map(authors_long, WikidataR::initials),
author_list = map(authors_short, \(x) str_c(x, collapse = ", ")),
title = full_works[["results"]][["title"]],
doi = full_works[["results"]][["doi"]],
journal = full_works[["results"]][["primary_location"]][["source"]][["display_name"]],
journal = case_when(is.na(journal) ~ "", TRUE ~ journal),
version = full_works[["results"]][["best_oa_location"]][["version"]],
type = case_when(version == "submittedVersion" ~ "Preprint", TRUE ~ "Journal"),
pub_year = full_works[["results"]][["publication_year"]],
date = ymd(full_works[["results"]][["publication_date"]]),
cited_by = full_works[["results"]][["cited_by_count"]],
cites_by_year = full_works[["results"]][["counts_by_year"]],
is_oa = full_works[["results"]][["best_oa_location"]][["is_oa"]],
item = paste0(author_list, ". ", pub_year, ". ", title, ". ", "<i>", journal, ".</i> ", "[", str_remove(doi, fixed("https://doi.org/")), "](", doi, ")")
) |>
mutate(
item = str_replace(item, short_name, paste0("<b>", short_name, "</b>")),
item = case_when(
is.na(is_oa) ~ paste0(item, " — [PDF](./assets/pdf/", str_replace_all(str_remove(doi, fixed("https://doi.org/")), "[\\./]", "_") , ".pdf)"),
TRUE ~ item)) |>
arrange(date) |>
drop_na(doi) |>
distinct(title, journal, .keep_all = TRUE)
#### Load data ####
orcid <- "0000-0003-3943-1476"
# Other authors for database testing:
# orcid <- "0000-0002-6959-3284" #Edouard
# orcid <- "0000-0002-6377-5132" #Staffan
# full_profile <- fromJSON("https://api.openalex.org/authors/A5046939400") #Lise
full_profile <- fromJSON(paste0("https://api.openalex.org/authors/orcid:", orcid))
full_works <- fromJSON(full_profile[["works_api_url"]])
full_peer_reviews <- orcid_peer_reviews(orcid)[[orcid]][["group"]][["peer-review-group"]] |>
unlist()
short_name <- WikidataR::initials(full_profile[["display_name"]])
works <- tibble(
authorship = full_works[["results"]][["authorships"]],
authors_long = map(authorship, c(2, 2)),
authors_short = map(authors_long, WikidataR::initials),
author_list = map(authors_short, \(x) str_c(x, collapse = ", ")),
title = full_works[["results"]][["title"]],
doi = full_works[["results"]][["doi"]],
journal_raw = full_works[["results"]][["primary_location"]][["source"]][["display_name"]],
journal = case_when(is.na(journal) ~ "", TRUE ~ journal),
version = full_works[["results"]][["best_oa_location"]][["version"]],
type = case_when(version == "submittedVersion" ~ "Preprint", TRUE ~ "Journal"),
pub_year = full_works[["results"]][["publication_year"]],
date = ymd(full_works[["results"]][["publication_date"]]),
cited_by = full_works[["results"]][["cited_by_count"]],
cites_by_year = full_works[["results"]][["counts_by_year"]],
is_oa = full_works[["results"]][["best_oa_location"]][["is_oa"]],
item = paste0(author_list, ". ", pub_year, ". ", title, ". ", "<i>", journal, ".</i> ", "[", str_remove(doi, fixed("https://doi.org/")), "](", doi, ")")
) |>
mutate(
item = str_replace(item, short_name, paste0("<b>", short_name, "</b>")),
item = case_when(
is.na(is_oa) ~ paste0(item, " — [PDF](./assets/pdf/", str_replace_all(str_remove(doi, fixed("https://doi.org/")), "[\\./]", "_") , ".pdf)"),
TRUE ~ item)) |>
arrange(date) |>
drop_na(doi) |>
distinct(title, journal, .keep_all = TRUE)
#### Load data ####
orcid <- "0000-0003-3943-1476"
# Other authors for database testing:
# orcid <- "0000-0002-6959-3284" #Edouard
# orcid <- "0000-0002-6377-5132" #Staffan
# full_profile <- fromJSON("https://api.openalex.org/authors/A5046939400") #Lise
full_profile <- fromJSON(paste0("https://api.openalex.org/authors/orcid:", orcid))
full_works <- fromJSON(full_profile[["works_api_url"]])
full_peer_reviews <- orcid_peer_reviews(orcid)[[orcid]][["group"]][["peer-review-group"]] |>
unlist()
short_name <- WikidataR::initials(full_profile[["display_name"]])
works <- tibble(
authorship = full_works[["results"]][["authorships"]],
authors_long = map(authorship, c(2, 2)),
authors_short = map(authors_long, WikidataR::initials),
author_list = map(authors_short, \(x) str_c(x, collapse = ", ")),
title = full_works[["results"]][["title"]],
doi = full_works[["results"]][["doi"]],
journal_raw = full_works[["results"]][["primary_location"]][["source"]][["display_name"]],
journal = case_when(is.na(journal_raw) ~ "", TRUE ~ journal_raw),
version = full_works[["results"]][["best_oa_location"]][["version"]],
type = case_when(version == "submittedVersion" ~ "Preprint", TRUE ~ "Journal"),
pub_year = full_works[["results"]][["publication_year"]],
date = ymd(full_works[["results"]][["publication_date"]]),
cited_by = full_works[["results"]][["cited_by_count"]],
cites_by_year = full_works[["results"]][["counts_by_year"]],
is_oa = full_works[["results"]][["best_oa_location"]][["is_oa"]],
item = paste0(author_list, ". ", pub_year, ". ", title, ". ", "<i>", journal, ".</i> ", "[", str_remove(doi, fixed("https://doi.org/")), "](", doi, ")")
) |>
mutate(
item = str_replace(item, short_name, paste0("<b>", short_name, "</b>")),
item = case_when(
is.na(is_oa) ~ paste0(item, " — [PDF](./assets/pdf/", str_replace_all(str_remove(doi, fixed("https://doi.org/")), "[\\./]", "_") , ".pdf)"),
TRUE ~ item)) |>
arrange(date) |>
drop_na(doi) |>
distinct(title, journal, .keep_all = TRUE)
work_table <- works |>
arrange(desc(date)) |>
select(
"Reference" = item,
"Citations" = cited_by,
"Year" = pub_year,
type
)
work_timeline <- works |>
select(doi, pub_year, type) |>
count(pub_year, type, name = "works") |>
complete(pub_year, type, fill = list(works = 0)) |>
group_by(type) |>
arrange(pub_year) |>
mutate(works_cum = cumsum(works))
cite_timeline <- tibble(
year = full_profile[["counts_by_year"]][["year"]],
cited_by_count = full_profile[["counts_by_year"]][["cited_by_count"]]
) |>
arrange(year)
cites_fiveyear <- works |>
select(doi, pub_year, cites_by_year) |>
unnest(cites_by_year) |>
filter(year > year(now()) - 5) |>
group_by(doi) |>
summarise(cited_by_count = sum(cited_by_count))
cites <- works |>
select(doi, pub_year, cites_by_year) |>
unnest(cites_by_year) |>
group_by(doi) |>
summarise(cited_by_count = sum(cited_by_count))
i10 <- cites |>
filter(cited_by_count >= 10) |>
count() |>
pull(n)
h <- h_index(cites$cited_by_count)
peer_reviews <- tibble(
review = full_peer_reviews[grepl("peer-review-summary.external-ids.external-id.external-id-value", names(full_peer_reviews))],
year = full_peer_reviews[grepl("peer-review-summary.completion-date.year.value", names(full_peer_reviews))]
) |>
summarise(count = n())
peer_reviews_fiveyear <- tibble(
review = full_peer_reviews[grepl("peer-review-summary.external-ids.external-id.external-id-value", names(full_peer_reviews))],
year = full_peer_reviews[grepl("peer-review-summary.completion-date.year.value", names(full_peer_reviews))]
) |>
filter(year > year(now()) - 5) |>
summarise(count = n())
metrics <- tibble(
metric = ordered(
rep(c("Citations", "h index", "i10 index", "Journal articles", "Preprints", "Peer reviews"), 2),
levels = rev(c("Citations", "h index", "i10 index", "Journal articles", "Preprints", "Peer reviews"))
),
span = ordered(
c(rep(c("Total", paste0("Since ", year(now()) - 5)), each = 6)),
levels = c("Total", paste0("Since ", year(now()) - 5))
),
value = c(
sum(cite_timeline$cited_by_count),
h,
i10,
max(work_timeline$works_cum[work_timeline$type == "Journal"]),
max(work_timeline$works_cum[work_timeline$type == "Preprint"]),
peer_reviews$count,
sum(cite_timeline$cited_by_count[cite_timeline$year > year(now()) - 5]),
h_index(cites_fiveyear$cited_by_count),
length(cites_fiveyear$cited_by_count[cites_fiveyear$cited_by_count >= 10]),
sum(work_timeline$works[cite_timeline$year > year(now()) - 5 & work_timeline$type == "Journal"]),
sum(work_timeline$works[cite_timeline$year > year(now()) - 5 & work_timeline$type == "Preprint"]),
peer_reviews_fiveyear$count
))
#### List papers ####
kable(
work_table |> filter(type == "Preprint") |> select(-type),
escape = FALSE
) |>
kable_styling(
html_font = "IBM Plex Sans",
full_width = FALSE
)
#### Load data ####
orcid <- "0000-0003-3943-1476"
# Other authors for database testing:
# orcid <- "0000-0002-6959-3284" #Edouard
# orcid <- "0000-0002-6377-5132" #Staffan
# full_profile <- fromJSON("https://api.openalex.org/authors/A5046939400") #Lise
full_profile <- fromJSON(paste0("https://api.openalex.org/authors/orcid:", orcid))
full_works <- fromJSON(full_profile[["works_api_url"]])
full_peer_reviews <- orcid_peer_reviews(orcid)[[orcid]][["group"]][["peer-review-group"]] |>
unlist()
short_name <- WikidataR::initials(full_profile[["display_name"]])
works <- tibble(
authorship = full_works[["results"]][["authorships"]],
authors_long = map(authorship, c(2, 2)),
authors_short = map(authors_long, WikidataR::initials),
author_list = map(authors_short, \(x) str_c(x, collapse = ", ")),
title = full_works[["results"]][["title"]],
doi = full_works[["results"]][["doi"]],
journal_raw = full_works[["results"]][["primary_location"]][["source"]][["display_name"]],
journal = case_when(is.na(journal_raw) ~ "bioRxiv (Cold Spring Harbor Laboratory)", TRUE ~ journal_raw),
version = full_works[["results"]][["best_oa_location"]][["version"]],
type = case_when(version == "submittedVersion" ~ "Preprint", TRUE ~ "Journal"),
pub_year = full_works[["results"]][["publication_year"]],
date = ymd(full_works[["results"]][["publication_date"]]),
cited_by = full_works[["results"]][["cited_by_count"]],
cites_by_year = full_works[["results"]][["counts_by_year"]],
is_oa = full_works[["results"]][["best_oa_location"]][["is_oa"]],
item = paste0(author_list, ". ", pub_year, ". ", title, ". ", "<i>", journal, ".</i> ", "[", str_remove(doi, fixed("https://doi.org/")), "](", doi, ")")
) |>
mutate(
item = str_replace(item, short_name, paste0("<b>", short_name, "</b>")),
item = case_when(
is.na(is_oa) ~ paste0(item, " — [PDF](./assets/pdf/", str_replace_all(str_remove(doi, fixed("https://doi.org/")), "[\\./]", "_") , ".pdf)"),
TRUE ~ item)) |>
arrange(date) |>
drop_na(doi) |>
distinct(title, journal, .keep_all = TRUE)
work_table <- works |>
arrange(desc(date)) |>
select(
"Reference" = item,
"Citations" = cited_by,
"Year" = pub_year,
type
)
work_timeline <- works |>
select(doi, pub_year, type) |>
count(pub_year, type, name = "works") |>
complete(pub_year, type, fill = list(works = 0)) |>
group_by(type) |>
arrange(pub_year) |>
mutate(works_cum = cumsum(works))
cite_timeline <- tibble(
year = full_profile[["counts_by_year"]][["year"]],
cited_by_count = full_profile[["counts_by_year"]][["cited_by_count"]]
) |>
arrange(year)
cites_fiveyear <- works |>
select(doi, pub_year, cites_by_year) |>
unnest(cites_by_year) |>
filter(year > year(now()) - 5) |>
group_by(doi) |>
summarise(cited_by_count = sum(cited_by_count))
cites <- works |>
select(doi, pub_year, cites_by_year) |>
unnest(cites_by_year) |>
group_by(doi) |>
summarise(cited_by_count = sum(cited_by_count))
i10 <- cites |>
filter(cited_by_count >= 10) |>
count() |>
pull(n)
h <- h_index(cites$cited_by_count)
peer_reviews <- tibble(
review = full_peer_reviews[grepl("peer-review-summary.external-ids.external-id.external-id-value", names(full_peer_reviews))],
year = full_peer_reviews[grepl("peer-review-summary.completion-date.year.value", names(full_peer_reviews))]
) |>
summarise(count = n())
peer_reviews_fiveyear <- tibble(
review = full_peer_reviews[grepl("peer-review-summary.external-ids.external-id.external-id-value", names(full_peer_reviews))],
year = full_peer_reviews[grepl("peer-review-summary.completion-date.year.value", names(full_peer_reviews))]
) |>
filter(year > year(now()) - 5) |>
summarise(count = n())
metrics <- tibble(
metric = ordered(
rep(c("Citations", "h index", "i10 index", "Journal articles", "Preprints", "Peer reviews"), 2),
levels = rev(c("Citations", "h index", "i10 index", "Journal articles", "Preprints", "Peer reviews"))
),
span = ordered(
c(rep(c("Total", paste0("Since ", year(now()) - 5)), each = 6)),
levels = c("Total", paste0("Since ", year(now()) - 5))
),
value = c(
sum(cite_timeline$cited_by_count),
h,
i10,
max(work_timeline$works_cum[work_timeline$type == "Journal"]),
max(work_timeline$works_cum[work_timeline$type == "Preprint"]),
peer_reviews$count,
sum(cite_timeline$cited_by_count[cite_timeline$year > year(now()) - 5]),
h_index(cites_fiveyear$cited_by_count),
length(cites_fiveyear$cited_by_count[cites_fiveyear$cited_by_count >= 10]),
sum(work_timeline$works[cite_timeline$year > year(now()) - 5 & work_timeline$type == "Journal"]),
sum(work_timeline$works[cite_timeline$year > year(now()) - 5 & work_timeline$type == "Preprint"]),
peer_reviews_fiveyear$count
))
#### List papers ####
kable(
work_table |> filter(type == "Preprint") |> select(-type),
escape = FALSE
) |>
kable_styling(
html_font = "IBM Plex Sans",
full_width = FALSE
)
